{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(mysql+pymysql://root:***@localhost:3306/testdb?charset=utf8)\n"
     ]
    }
   ],
   "source": [
    "engine=create_engine('mysql+pymysql://root:Cuiqin:233@localhost:3306/testdb?charset=utf8',encoding='utf-8',echo=True)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-19 08:22:59,356 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2020-03-19 08:22:59,357 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,374 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2020-03-19 08:22:59,374 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,379 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2020-03-19 08:22:59,380 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,382 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'\n",
      "2020-03-19 08:22:59,384 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,393 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 08:22:59,393 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,395 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 08:22:59,396 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,397 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\n",
      "2020-03-19 08:22:59,398 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,401 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 08:22:59,402 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,411 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 08:22:59,411 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,423 INFO sqlalchemy.engine.base.Engine SHOW CREATE TABLE `meal_order_detail1`\n",
      "2020-03-19 08:22:59,424 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:22:59,435 INFO sqlalchemy.engine.base.Engine SELECT meal_order_detail1.detail_id, meal_order_detail1.order_id, meal_order_detail1.dishes_id, meal_order_detail1.logicprn_name, meal_order_detail1.parent_class_name, meal_order_detail1.dishes_name, meal_order_detail1.itemis_add, meal_order_detail1.counts, meal_order_detail1.amounts, meal_order_detail1.cost, meal_order_detail1.place_order_time, meal_order_detail1.discount_amt, meal_order_detail1.discount_reason, meal_order_detail1.kick_back, meal_order_detail1.add_inprice, meal_order_detail1.add_info, meal_order_detail1.bar_code, meal_order_detail1.picture_file, meal_order_detail1.emp_id \n",
      "FROM meal_order_detail1\n",
      "2020-03-19 08:22:59,436 INFO sqlalchemy.engine.base.Engine {}\n",
      "分组以后 <pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000027381E67EC8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n",
      "S:\\Anaconda\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 1\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "detail = pd.read_sql_table('meal_order_detail1',\n",
    "                          con=engine)\n",
    "detailGroup = detail[['order_id','counts',\n",
    "                     'amounts']].groupby(by='order_id')\n",
    "print('分组以后',detailGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前五组每组的均值：\n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002      1.0000   32.000\n",
      "1003      1.2500   30.125\n",
      "1004      1.0625   43.875\n",
      "1008      1.0000   63.000\n",
      "1011      1.0000   57.700\n"
     ]
    }
   ],
   "source": [
    "print('前五组每组的均值：\\n',detailGroup.mean().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每组均值：detailGroup           counts  amounts\n",
      "order_id                 \n",
      "1002      1.0000   32.000\n",
      "1003      1.2500   30.125\n",
      "1004      1.0625   43.875\n",
      "1008      1.0000   63.000\n",
      "1011      1.0000   57.700\n"
     ]
    }
   ],
   "source": [
    "print('每组均值：detailGroup',detailGroup.mean().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前五组每组的标准差：\n",
      "            counts    amounts\n",
      "order_id                    \n",
      "1002      0.00000  16.000000\n",
      "1003      0.46291  21.383822\n",
      "1004      0.25000  31.195886\n",
      "1008      0.00000  64.880660\n",
      "1011      0.00000  50.077828\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前五组每组的标准差：\\n',\n",
    "     detailGroup.std().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后每5组的大小为：\n",
      " order_id\n",
      "1002     7\n",
      "1003     8\n",
      "1004    16\n",
      "1008     5\n",
      "1011    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后每5组的大小为：\\n',\n",
    "     detailGroup.size().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品销售与售价的和与均值:\n",
      "            counts        amounts\n",
      "sum   3088.000000  125992.000000\n",
      "mean     1.111191      45.337172\n"
     ]
    }
   ],
   "source": [
    "print('菜品销售与售价的和与均值:\\n',\n",
    "     detail[['counts','amounts']].agg([np.sum,np.mean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销售总和与售价的均值：\n",
      " counts     3088.000000\n",
      "amounts      45.337172\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销售总和与售价的均值：\\n',\n",
    "    detail.agg({'counts':np.sum,'amounts':np.mean})) # 第二种分别求字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品订单详情表的菜品销售综合与售价的总和与均值为:\n",
      "       counts        amounts\n",
      "mean     NaN      45.337172\n",
      "sum   3088.0  125992.000000\n"
     ]
    }
   ],
   "source": [
    "print('菜品订单详情表的菜品销售综合与售价的总和与均值为:\\n',\n",
    "     detail.agg({'counts':np.sum,'amounts':[np.mean,np.sum]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售总和两倍：\n",
      " counts    6176.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 自定义函数求两倍的和\n",
    "def DoubleSum(data):\n",
    "    s = data.sum()*2\n",
    "    return s\n",
    "print(\"销售总和两倍：\\n\",\n",
    "     detail.agg({'counts':DoubleSum},axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售总和两倍:\n",
      "    counts\n",
      "0     2.0\n",
      "1     2.0\n",
      "2     2.0\n",
      "3     2.0\n",
      "4     2.0\n"
     ]
    }
   ],
   "source": [
    "def DoubleSum_np(data):\n",
    "    s = np.sum(data)*2\n",
    "    return s\n",
    "print('销售总和两倍:\\n',\n",
    "     detail.agg({'counts':DoubleSum_np},axis=0).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售与售价的和的两倍为:\n",
      " counts       6176.0\n",
      "amounts    251984.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('销售与售价的和的两倍为:\\n',\n",
    "     detail[['counts','amounts']].agg(DoubleSum_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的均值为：\n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002      1.0000   32.000\n",
      "1003      1.2500   30.125\n",
      "1004      1.0625   43.875\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的均值为：\\n',\n",
    "     detailGroup.agg(np.mean).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情分组前3足每组菜品总数和售价均值为:\n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002         7.0   32.000\n",
      "1003        10.0   30.125\n",
      "1004        17.0   43.875\n"
     ]
    }
   ],
   "source": [
    "print('订单详情分组前3足每组菜品总数和售价均值为:\\n',\n",
    "     detailGroup.agg({'counts':np.sum,'amounts':np.mean}).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply聚合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销售与售价的均值为：\n",
      " counts      1.111191\n",
      "amounts    45.337172\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销售与售价的均值为：\\n',\n",
    "     detail[['counts','amounts']].apply(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的均值为:\n",
      "               order_id  counts  amounts\n",
      "order_id                               \n",
      "1002      1.431572e+26  1.0000   32.000\n",
      "1003      1.253875e+30  1.2500   30.125\n",
      "1004      6.275628e+61  1.0625   43.875\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的均值为:\\n',\n",
    "     detailGroup.apply(np.mean).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的标准差为:\n",
      "             counts    amounts\n",
      "order_id                     \n",
      "1002      0.000000  14.813122\n",
      "1003      0.433013  20.002734\n",
      "1004      0.242061  30.205287\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的标准差为:\\n',\n",
    "     detailGroup.apply(np.std).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "彩屏销售与售价的两倍为：\n",
      "    counts  amounts\n",
      "0     2.0     98.0\n",
      "1     2.0     96.0\n",
      "2     2.0     60.0\n",
      "3     2.0     50.0\n"
     ]
    }
   ],
   "source": [
    "# transform聚合\n",
    "print('彩屏销售与售价的两倍为：\\n',\n",
    "     detail[['counts','amounts']].transform(\n",
    "     lambda x:x*2).head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "('float division by zero', 'occurred at index counts')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-eeb71a718805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m print('分组后实现内离差标准化后前5行：\\n',\n\u001b[1;32m----> 2\u001b[1;33m      detailGroup.transform(lambda x:(x.mean()-x.min())/(x.max()-x.min())).head())\n\u001b[0m",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;31m# a reduction transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_transform_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[1;31m# Try slow path and fast path.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_choose_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_item_by_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_choose_path\u001b[1;34m(self, fast_path, slow_path, group)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_choose_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;31m# if we make it here, test if we can use the fast path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mfast_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             slow_path = lambda group: group.apply(\n\u001b[1;32m--> 627\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m             )\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6911\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6912\u001b[0m         )\n\u001b[1;32m-> 6913\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6915\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mfast_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             slow_path = lambda group: group.apply(\n\u001b[1;32m--> 627\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m             )\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-eeb71a718805>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m print('分组后实现内离差标准化后前5行：\\n',\n\u001b[1;32m----> 2\u001b[1;33m      detailGroup.transform(lambda x:(x.mean()-x.min())/(x.max()-x.min())).head())\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: ('float division by zero', 'occurred at index counts')"
     ]
    }
   ],
   "source": [
    "print('分组后实现内离差标准化后前5行：\\n',\n",
    "     detailGroup.transform(lambda x:(x.mean()-x.min())/(x.max()-x.min())).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照时间对菜品订单详情表进行拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-19 08:50:57,692 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2020-03-19 08:50:57,692 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,696 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2020-03-19 08:50:57,696 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,699 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2020-03-19 08:50:57,700 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,701 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'\n",
      "2020-03-19 08:50:57,701 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,705 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 08:50:57,706 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,707 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 08:50:57,707 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,709 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\n",
      "2020-03-19 08:50:57,710 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,713 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 08:50:57,714 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,718 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 08:50:57,718 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,721 INFO sqlalchemy.engine.base.Engine SHOW CREATE TABLE `meal_order_detail1`\n",
      "2020-03-19 08:50:57,722 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 08:50:57,726 INFO sqlalchemy.engine.base.Engine SELECT meal_order_detail1.detail_id, meal_order_detail1.order_id, meal_order_detail1.dishes_id, meal_order_detail1.logicprn_name, meal_order_detail1.parent_class_name, meal_order_detail1.dishes_name, meal_order_detail1.itemis_add, meal_order_detail1.counts, meal_order_detail1.amounts, meal_order_detail1.cost, meal_order_detail1.place_order_time, meal_order_detail1.discount_amt, meal_order_detail1.discount_reason, meal_order_detail1.kick_back, meal_order_detail1.add_inprice, meal_order_detail1.add_info, meal_order_detail1.bar_code, meal_order_detail1.picture_file, meal_order_detail1.emp_id \n",
      "FROM meal_order_detail1\n",
      "2020-03-19 08:50:57,727 INFO sqlalchemy.engine.base.Engine {}\n",
      "前五组每组的数目为：\n",
      " date\n",
      "2016-08-01    217\n",
      "2016-08-02    138\n",
      "2016-08-03    157\n",
      "2016-08-04    144\n",
      "2016-08-05    193\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine=create_engine('mysql+pymysql://root:Cuiqin:233@localhost:3306/testdb?charset=utf8',encoding=\"utf-8\",echo=True)\n",
    "detail = pd.read_sql_table('meal_order_detail1',con=engine)\n",
    "detail['place_order_time'] = pd.to_datetime(\n",
    "detail['place_order_time'])\n",
    "detail['date'] = [i.date() for i in detail['place_order_time']]\n",
    "detailGroup = detail[['date','counts','amounts']].groupby(by='date')\n",
    "print('前五组每组的数目为：\\n',\n",
    "     detailGroup.size().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前五组单日菜品销售均价为：\n",
      "               amounts\n",
      "date                 \n",
      "2016-08-01  43.161290\n",
      "2016-08-02  44.384058\n",
      "2016-08-03  43.885350\n",
      "2016-08-04  52.423611\n",
      "2016-08-05  44.927461\n"
     ]
    }
   ],
   "source": [
    "dayMean = detailGroup.agg({'amounts':np.mean})\n",
    "print('前五组单日菜品销售均价为：\\n',dayMean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前5组单日菜品销售中位数为:\n",
      "             amounts\n",
      "date               \n",
      "2016-08-01     33.0\n",
      "2016-08-02     35.0\n",
      "2016-08-03     38.0\n",
      "2016-08-04     39.0\n",
      "2016-08-05     37.0\n"
     ]
    }
   ],
   "source": [
    "dayMedian = detailGroup.agg({'amounts':np.median})\n",
    "print('前5组单日菜品销售中位数为:\\n',dayMedian.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前5组单日菜品售出数目为:\n",
      " date\n",
      "2016-08-01    233.0\n",
      "2016-08-02    151.0\n",
      "2016-08-03    192.0\n",
      "2016-08-04    169.0\n",
      "2016-08-05    224.0\n",
      "Name: counts, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daySaleSum = detailGroup.apply(np.sum)['counts']\n",
    "print('前5组单日菜品售出数目为:\\n',daySaleSum.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-19 09:01:21,583 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2020-03-19 09:01:21,584 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,588 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2020-03-19 09:01:21,589 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,593 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2020-03-19 09:01:21,594 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,595 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'\n",
      "2020-03-19 09:01:21,596 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,600 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 09:01:21,601 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,602 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 09:01:21,602 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,603 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\n",
      "2020-03-19 09:01:21,604 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,606 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 09:01:21,607 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,611 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 09:01:21,612 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,615 INFO sqlalchemy.engine.base.Engine SHOW CREATE TABLE `meal_order_detail1`\n",
      "2020-03-19 09:01:21,616 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:01:21,621 INFO sqlalchemy.engine.base.Engine SELECT meal_order_detail1.detail_id, meal_order_detail1.order_id, meal_order_detail1.dishes_id, meal_order_detail1.logicprn_name, meal_order_detail1.parent_class_name, meal_order_detail1.dishes_name, meal_order_detail1.itemis_add, meal_order_detail1.counts, meal_order_detail1.amounts, meal_order_detail1.cost, meal_order_detail1.place_order_time, meal_order_detail1.discount_amt, meal_order_detail1.discount_reason, meal_order_detail1.kick_back, meal_order_detail1.add_inprice, meal_order_detail1.add_info, meal_order_detail1.bar_code, meal_order_detail1.picture_file, meal_order_detail1.emp_id \n",
      "FROM meal_order_detail1\n",
      "2020-03-19 09:01:21,623 INFO sqlalchemy.engine.base.Engine {}\n",
      "以order_id作为分组创建的订单透视表为：\n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002       32.000  1.0000\n",
      "1003       30.125  1.2500\n",
      "1004       43.875  1.0625\n",
      "1008       63.000  1.0000\n",
      "1011       57.700  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n",
      "S:\\Anaconda\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 1\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine=create_engine('mysql+pymysql://root:Cuiqin:233@localhost:3306/testdb?charset=utf8',encoding='utf-8',echo=True)\n",
    "detail = pd.read_sql_table('meal_order_detail1',\n",
    "                          con=engine)\n",
    "detailPivot = pd.pivot_table(detail[[\n",
    "    'order_id',\n",
    "    'counts',\n",
    "    'amounts']],index='order_id')\n",
    "print('以order_id作为分组创建的订单透视表为：\\n',\n",
    "     detailPivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id作为分组键创建的订单销售与售价总和透视表为:\n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002        224.0     7.0\n",
      "1003        241.0    10.0\n",
      "1004        702.0    17.0\n",
      "1008        315.0     5.0\n",
      "1011        577.0    10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot1 = pd.pivot_table(detail[[\n",
    "    'order_id',\n",
    "    'counts',\n",
    "    'amounts'\n",
    "]],index='order_id',aggfunc=np.sum)\n",
    "print('order_id作为分组键创建的订单销售与售价总和透视表为:\\n',\n",
    "     detailPivot1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个索引值创建的查询操作的透视表为：\n",
      "                       amounts  counts\n",
      "order_id dishes_name                 \n",
      "1002     凉拌菠菜            27.0     1.0\n",
      "         南瓜枸杞小饼干         19.0     1.0\n",
      "         焖猪手             58.0     1.0\n",
      "         独家薄荷鲜虾牛肉卷       45.0     1.0\n",
      "         白胡椒胡萝卜羊肉汤       35.0     1.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot2 = pd.pivot_table(detail[[\n",
    "    'order_id','dishes_name',\n",
    "    'counts','amounts'\n",
    "]],index=['order_id','dishes_name'\n",
    "         ],aggfunc=np.sum)\n",
    "print('两个索引值创建的查询操作的透视表为：\\n',\n",
    "     detailPivot2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id+dishes_name：\n",
      "             amounts                        \n",
      "dishes_name  42度海之蓝  北冰洋汽水  38度剑南春  50度古井贡酒\n",
      "order_id                                   \n",
      "1002            NaN     NaN     NaN     NaN\n",
      "1003            NaN     NaN     NaN     NaN\n",
      "1004            NaN     NaN     NaN     NaN\n",
      "1008            NaN     NaN     NaN     NaN\n",
      "1011           99.0     NaN     NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "detailPiovt2 = pd.pivot_table(detail[[\n",
    "    'order_id','dishes_name','counts','amounts'\n",
    "    ]],index='order_id',columns='dishes_name',aggfunc=np.sum)\n",
    "print('order_id+dishes_name：\\n',detailPiovt2.iloc[:5,:4])\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "透视前5行：\n",
      "           counts\n",
      "order_id        \n",
      "1002         7.0\n",
      "1003        10.0\n",
      "1004        17.0\n",
      "1008         5.0\n",
      "1011        10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot4=pd.pivot_table(detail[[\n",
    "    'order_id','dishes_name','counts','amounts'\n",
    "]],index='order_id',values='counts',aggfunc=np.sum)\n",
    "print('透视前5行：\\n',detailPivot4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            amounts                        \n",
      "dishes_name  42度海之蓝  北冰洋汽水  38度剑南春  50度古井贡酒\n",
      "order_id                                   \n",
      "1002              0       0       0       0\n",
      "1003              0       0       0       0\n",
      "1004              0       0       0       0\n",
      "1008              0       0       0       0\n",
      "1011             99       0       0       0\n"
     ]
    }
   ],
   "source": [
    "detailPiovt5=pd.pivot_table(detail[[\n",
    "    'order_id','dishes_name','counts','amounts'\n",
    "]],index='order_id',columns='dishes_name',aggfunc=np.sum,fill_value=0)\n",
    "print(detailPiovt5.iloc[:5,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分组(order_id and dishes_name)：\n",
      "             counts                    \n",
      "dishes_name 黄油曲奇饼干 黄花菜炒木耳 黑米恋上葡萄   All\n",
      "order_id                              \n",
      "1002             0      0      0   7.0\n",
      "1003             0      0      0  10.0\n",
      "1004             0      1      0  17.0\n",
      "1008             0      0      0   5.0\n",
      "1011             0      0      0  10.0\n"
     ]
    }
   ],
   "source": [
    "#透视表中添加汇总数据\n",
    "detailPivot6=pd.pivot_table(detail[[\n",
    "    'order_id','dishes_name','counts','amounts'\n",
    "]],index='order_id',columns='dishes_name',aggfunc=np.sum,fill_value=0,margins=True)\n",
    "print('分组(order_id and dishes_name)：\\n',detailPivot6.iloc[:5,-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dishes_name   42度海之蓝   北冰洋汽水   38度剑南春   50度古井贡酒  52度泸州老窖 \n",
      "order_id                                                 \n",
      "1002             NaN      NaN      NaN      NaN       NaN\n",
      "1003             NaN      NaN      NaN      NaN       NaN\n",
      "1004             NaN      NaN      NaN      NaN       NaN\n",
      "1008             NaN      NaN      NaN      NaN       NaN\n",
      "1011             1.0      NaN      NaN      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# crosstable 制作 交叉表\n",
    "detailCross = pd.crosstab(index=detail['order_id'],columns=detail['dishes_name'],values=detail['counts'],aggfunc=np.sum)\n",
    "print(detailCross.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务实现2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-19 09:31:48,743 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode'\n",
      "2020-03-19 09:31:48,745 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,748 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names'\n",
      "2020-03-19 09:31:48,748 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,753 INFO sqlalchemy.engine.base.Engine SELECT DATABASE()\n",
      "2020-03-19 09:31:48,753 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,755 INFO sqlalchemy.engine.base.Engine show collation where `Charset` = 'utf8mb4' and `Collation` = 'utf8mb4_bin'\n",
      "2020-03-19 09:31:48,756 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,759 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 09:31:48,760 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,761 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS CHAR(60)) AS anon_1\n",
      "2020-03-19 09:31:48,762 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,763 INFO sqlalchemy.engine.base.Engine SELECT CAST('test collated returns' AS CHAR CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\n",
      "2020-03-19 09:31:48,764 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,765 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 09:31:48,765 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,768 INFO sqlalchemy.engine.base.Engine SHOW FULL TABLES FROM `testdb`\n",
      "2020-03-19 09:31:48,768 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,770 INFO sqlalchemy.engine.base.Engine SHOW CREATE TABLE `meal_order_detail1`\n",
      "2020-03-19 09:31:48,771 INFO sqlalchemy.engine.base.Engine {}\n",
      "2020-03-19 09:31:48,775 INFO sqlalchemy.engine.base.Engine SELECT meal_order_detail1.detail_id, meal_order_detail1.order_id, meal_order_detail1.dishes_id, meal_order_detail1.logicprn_name, meal_order_detail1.parent_class_name, meal_order_detail1.dishes_name, meal_order_detail1.itemis_add, meal_order_detail1.counts, meal_order_detail1.amounts, meal_order_detail1.cost, meal_order_detail1.place_order_time, meal_order_detail1.discount_amt, meal_order_detail1.discount_reason, meal_order_detail1.kick_back, meal_order_detail1.add_inprice, meal_order_detail1.add_info, meal_order_detail1.bar_code, meal_order_detail1.picture_file, meal_order_detail1.emp_id \n",
      "FROM meal_order_detail1\n",
      "2020-03-19 09:31:48,776 INFO sqlalchemy.engine.base.Engine {}\n",
      "            amounts  counts\n",
      "date                       \n",
      "2016-08-01   9366.0   233.0\n",
      "2016-08-02   6125.0   151.0\n",
      "2016-08-03   6890.0   192.0\n",
      "2016-08-04   7549.0   169.0\n",
      "2016-08-05   8671.0   224.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine=create_engine('mysql+pymysql://root:Cuiqin:233@localhost:3306/testdb?charset=utf8',encoding='utf-8',echo=True)\n",
    "detail = pd.read_sql_table('meal_order_detail1',con=engine)\n",
    "detail['place_order_time']=pd.to_datetime(detail['place_order_time'])\n",
    "detail['date'] = [i.date() for i in detail['place_order_time']]\n",
    "PivotDetail = pd.pivot_table(detail[[\n",
    "    'date','dishes_name','counts','amounts'\n",
    "]],index='date',aggfunc=np.sum,margins=True)\n",
    "print(PivotDetail.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单个菜品单日成交总额交叉表后5，5：\n",
      " dishes_name\n",
      "黄尾袋鼠西拉子红葡萄酒      230.0\n",
      "黄油曲奇饼干            32.0\n",
      "黄花菜炒木耳           105.0\n",
      "黑米恋上葡萄            99.0\n",
      "All            31306.0\n",
      "Name: 2016-08-07, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "CrossDetail1 = pd.crosstab(index=detail['date'],\n",
    "                            columns=detail['dishes_name'],values=detail['amounts'],aggfunc=np.sum,margins=True)\n",
    "print('单个菜品单日成交总额交叉表后5，5：\\n',\n",
    "     CrossDetail1.iloc[-5,-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
