{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除表情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "import re\n",
    "\n",
    "\n",
    "def filter_emoji(desstr, restr=''):\n",
    "    # 过滤表情\n",
    "    try:\n",
    "        co = re.compile(u'[\\U00010000-\\U0010ffff]')\n",
    "    except re.error:\n",
    "        co = re.compile(u'[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]')\n",
    "    return co.sub(restr, desstr)\n",
    "\n",
    "\n",
    "def data_filter(content, lower):\n",
    "    # 1.去掉html标记\n",
    "    html = content.strip()\n",
    "    html = html.strip(\"\\n\")\n",
    "    result = []\n",
    "    parse = HTMLParser()\n",
    "    parse.handle_data = result.append\n",
    "    parse.feed(html)\n",
    "    parse.close()\n",
    "    content = \"\".join(result)\n",
    "\n",
    "    # 2.去掉url标记\n",
    "    r1 = '''http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'''\n",
    "    content = re.sub(r1, '', content)\n",
    "\n",
    "    # 3.去掉@标记与@某人的标记\n",
    "    r2 = \"(@.*?)+ \"\n",
    "    content = re.sub(r2, '', content)\n",
    "    content = re.sub(r\"(回复)?(//)?\\s*@\\S*?\\s*(:| |$)\", \" \", content)\n",
    "\n",
    "    # 4.去掉一些特殊字符\n",
    "    r3 = u'[’!\"#$%&\\'()*+,-./:;<=>?@；；：．｜～\\≧▽—°❄×☝➡️❤️⭐■⏰🎂🌕👇🤔📷🎤🉑➕🥑👍📒🥚📹🆔🍊☁✨📍💝👗🚄🍀🐾🍓🐋▲🔺🔗❗🦐🐫🧜‍🏃👇➕♥♀☀●巜「」☕／↓→<=>?@⁄•ω★💊🙈☕💰😂·、…★、…【】《》『』（）？“”‘’！[\\\\]^_`{|}~]+'\n",
    "    content = re.sub(r3, '', content)\n",
    "\n",
    "    # 5.过滤表情\n",
    "    content = filter_emoji(content, restr='')\n",
    "    content = re.sub(r\"\\[\\S+\\]\", \"\", content)  # 去除表情符号\n",
    "\n",
    "    # 6.合并正文中过多的空格\n",
    "    content = re.sub(r\"\\s+\", \" \", content)\n",
    "\n",
    "    # 7.过滤掉\\ax0\n",
    "    content = content.strip().replace(u'\\u3000', u'').replace(u'\\xa0', u'')\n",
    "\n",
    "    # 8.是否转换为小写\n",
    "    if lower:\n",
    "        content = str(content).lower()\n",
    "\n",
    "    return content.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 9 fields in line 10397, saw 17\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fd21190a636e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mori_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../before/test2\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtextType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mori_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtextType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# 去除表情\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mS:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 9 fields in line 10397, saw 17\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "ori_path = \"../before/test2\"\n",
    "textType = \".csv\"\n",
    "df = pandas.read_csv(ori_path+textType)\n",
    "# 去除表情\n",
    "for i in range(df.shape[0]):\n",
    "    df.loc[i,'text'] = data_filter(df.loc[i,'text'],True)\n",
    "after_path = ori_path+\"_new\"\n",
    "df.to_csv(after_path+textType,index=False, encoding='utf-8')\n",
    "# 去除null值\n",
    "d = pandas.read_csv(after_path+textType)\n",
    "d.dropna(subset=['text'],inplace=True)\n",
    "end_path = after_path+\"_end\"\n",
    "d.to_csv(end_path+textType,index=False,encoding='utf-8')\n",
    "# 检验数据\n",
    "e = pandas.read_csv(end_path+textType)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除重复项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>uid</th>\n",
       "      <th>like_count</th>\n",
       "      <th>username</th>\n",
       "      <th>following</th>\n",
       "      <th>followed</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4529878760164897</td>\n",
       "      <td>Thu Jul 23 15:52:00 +0800 2020</td>\n",
       "      <td>不需要这么做因为5g天线放进口罩已经足以控制你们了</td>\n",
       "      <td>3101630921</td>\n",
       "      <td>96</td>\n",
       "      <td>我姓倪别的不能说了</td>\n",
       "      <td>194</td>\n",
       "      <td>2219</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4529882221249717</td>\n",
       "      <td>Thu Jul 23 16:05:44 +0800 2020</td>\n",
       "      <td>比亚迪的口罩有5g芯片，千万别用</td>\n",
       "      <td>2296948284</td>\n",
       "      <td>数据缺失</td>\n",
       "      <td>成成成小四</td>\n",
       "      <td>153</td>\n",
       "      <td>312</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4529882136315032</td>\n",
       "      <td>Thu Jul 23 16:05:24 +0800 2020</td>\n",
       "      <td>5g天线我控制这些木鱼脑袋干啥呀，闲的吗</td>\n",
       "      <td>6458970173</td>\n",
       "      <td>数据缺失</td>\n",
       "      <td>不超过十个</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4529881889905876</td>\n",
       "      <td>Thu Jul 23 16:04:26 +0800 2020</td>\n",
       "      <td>现在我每天在这里8买各种赛今天又收获满满cbanba典静其拍啥都有一边玩一边收米今天提线六千...</td>\n",
       "      <td>2173015011</td>\n",
       "      <td>233</td>\n",
       "      <td>月季哥哥阿</td>\n",
       "      <td>67</td>\n",
       "      <td>1553</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4529878547050775</td>\n",
       "      <td>Thu Jul 23 15:51:09 +0800 2020</td>\n",
       "      <td>这还真的需要专门辟谣</td>\n",
       "      <td>1895755777</td>\n",
       "      <td>38</td>\n",
       "      <td>行者居无修</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>4529402060739036</td>\n",
       "      <td>Wed Jul 22 08:17:46 +0800 2020</td>\n",
       "      <td>目前死亡率还真不算高，大概千分之六到千分之十。这要真能能引发自身免疫疾病，后遗症就太可怕了，...</td>\n",
       "      <td>7435445676</td>\n",
       "      <td>0</td>\n",
       "      <td>马谡不参军</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8356</td>\n",
       "      <td>4529393303030767</td>\n",
       "      <td>Wed Jul 22 07:42:58 +0800 2020</td>\n",
       "      <td>今天找找红契约，撕了看看能不能改变国运</td>\n",
       "      <td>3956503775</td>\n",
       "      <td>0</td>\n",
       "      <td>三元桥式神</td>\n",
       "      <td>474</td>\n",
       "      <td>736</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8357</td>\n",
       "      <td>4529386370370931</td>\n",
       "      <td>Wed Jul 22 07:15:25 +0800 2020</td>\n",
       "      <td>早上好</td>\n",
       "      <td>3320500013</td>\n",
       "      <td>0</td>\n",
       "      <td>请叫我厕所所长</td>\n",
       "      <td>5201</td>\n",
       "      <td>170664</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8358</td>\n",
       "      <td>4529638494443206</td>\n",
       "      <td>Wed Jul 22 23:57:16 +0800 2020</td>\n",
       "      <td>太好了</td>\n",
       "      <td>5365388364</td>\n",
       "      <td>0</td>\n",
       "      <td>桃子82724</td>\n",
       "      <td>987</td>\n",
       "      <td>103</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8359</td>\n",
       "      <td>4529426543150147</td>\n",
       "      <td>Wed Jul 22 09:55:02 +0800 2020</td>\n",
       "      <td>辛苦了</td>\n",
       "      <td>5013976920</td>\n",
       "      <td>0</td>\n",
       "      <td>janechen1213</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8360 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   wid                            time  \\\n",
       "0     4529878760164897  Thu Jul 23 15:52:00 +0800 2020   \n",
       "1     4529882221249717  Thu Jul 23 16:05:44 +0800 2020   \n",
       "2     4529882136315032  Thu Jul 23 16:05:24 +0800 2020   \n",
       "3     4529881889905876  Thu Jul 23 16:04:26 +0800 2020   \n",
       "4     4529878547050775  Thu Jul 23 15:51:09 +0800 2020   \n",
       "...                ...                             ...   \n",
       "8355  4529402060739036  Wed Jul 22 08:17:46 +0800 2020   \n",
       "8356  4529393303030767  Wed Jul 22 07:42:58 +0800 2020   \n",
       "8357  4529386370370931  Wed Jul 22 07:15:25 +0800 2020   \n",
       "8358  4529638494443206  Wed Jul 22 23:57:16 +0800 2020   \n",
       "8359  4529426543150147  Wed Jul 22 09:55:02 +0800 2020   \n",
       "\n",
       "                                                   text         uid  \\\n",
       "0                             不需要这么做因为5g天线放进口罩已经足以控制你们了  3101630921   \n",
       "1                                      比亚迪的口罩有5g芯片，千万别用  2296948284   \n",
       "2                                  5g天线我控制这些木鱼脑袋干啥呀，闲的吗  6458970173   \n",
       "3     现在我每天在这里8买各种赛今天又收获满满cbanba典静其拍啥都有一边玩一边收米今天提线六千...  2173015011   \n",
       "4                                            这还真的需要专门辟谣  1895755777   \n",
       "...                                                 ...         ...   \n",
       "8355  目前死亡率还真不算高，大概千分之六到千分之十。这要真能能引发自身免疫疾病，后遗症就太可怕了，...  7435445676   \n",
       "8356                                今天找找红契约，撕了看看能不能改变国运  3956503775   \n",
       "8357                                                早上好  3320500013   \n",
       "8358                                                太好了  5365388364   \n",
       "8359                                                辛苦了  5013976920   \n",
       "\n",
       "     like_count      username  following  followed gender  \n",
       "0            96     我姓倪别的不能说了        194      2219      m  \n",
       "1          数据缺失         成成成小四        153       312      m  \n",
       "2          数据缺失         不超过十个         14        17      m  \n",
       "3           233         月季哥哥阿         67      1553      m  \n",
       "4            38         行者居无修        126       105      f  \n",
       "...         ...           ...        ...       ...    ...  \n",
       "8355          0         马谡不参军         43        22      m  \n",
       "8356          0         三元桥式神        474       736      f  \n",
       "8357          0       请叫我厕所所长       5201    170664      f  \n",
       "8358          0       桃子82724        987       103      m  \n",
       "8359          0  janechen1213         70        77      f  \n",
       "\n",
       "[8360 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为去重和去除表情已经在录入时处理所以只需要进行重复项去除\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "name = \"test2_new_end.csv\"\n",
    "ori_path = \"../before/\"+name\n",
    "df = pd.read_csv(ori_path)\n",
    "newdf = df.drop_duplicates(subset=['wid'],keep=\"first\")\n",
    "new_path = \"../after/\"+name\n",
    "newdf.to_csv(new_path,index=False,encoding='utf-8')\n",
    "# 检验\n",
    "d = pd.read_csv(new_path)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
